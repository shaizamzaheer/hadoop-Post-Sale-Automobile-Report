{"cells":[{"cell_type":"code","source":["file_location = \"/FileStore/tables/data.csv\"\n\n#Read data.csv\nraw_rdd = spark.sparkContext.textFile(file_location)\n\n# the map output key should be vin_number, value should be the make and year, along with the incident type.\ndef extract_vin_key_value(line):\n    line = line.split(\",\")\n    return (\n        (line[2]),(line[3],line[5],line[1])\n    )\n\nvin_kv = raw_rdd.map(lambda x: extract_vin_key_value(x))\n\n\n# Perform group aggregation to populate make and year to all the records.\n# Like the reducer in MapReduce framework, Spark provides a “groupByKey” function to achieve\n# shuffle and sort in order to aggregate all records sharing the same key to the same groups.\n# Within a group of vin_number, we need to iterate through all the records and find the one that\n# has the make and year available and capture it in group level master info. As we filter and\n# output accident records, those records need to be modified adding the master info that we\n# captured in the first iterations\n\ndef populate_make(line):\n    lines = list(line)\n    initial_sales = [x for x in lines if x[2]=='I']\n    accidents = [x for x in lines if x[2]=='A']\n    zipped = list(zip(initial_sales, accidents))\n    return [(x[0],x[1],y[2]) for x,y in zipped]\n    \nenhance_make = vin_kv.groupByKey().flatMap(lambda kv: populate_make(kv[1]))\n\n\n# Map to get a RDD of ((make, year),1)\nmake_kv = enhance_make.map(lambda x: ((x[0],x[1]),1))\n\n\n# ReduceByKey for of accidents by make and year\naccident_rec_per_year = make_kv.reduceByKey(lambda x,y: x+y)\n\n# format properly\naccident_rec_per_year_format = accident_rec_per_year.map(lambda x:x[0][0]+\"-\"+x[0][1]+\",\"+str(x[1]))\n\n# # Save as text file\naccident_rec_per_year_format.saveAsTextFile(\"car_accidents_count\")\n\naccident_rec_per_year_format.take(20)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b3c13ac-6f6d-4d76-a76c-2df474c34127"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: ['Mercedes-2015,2', 'Mercedes-2016,1', 'Nissan-2003,1']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: ['Mercedes-2015,2', 'Mercedes-2016,1', 'Nissan-2003,1']"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57dfa0bc-9e7f-45a6-b67b-f103b0788a05"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spark mini Project","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3731929868712698}},"nbformat":4,"nbformat_minor":0}
